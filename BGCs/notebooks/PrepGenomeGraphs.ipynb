{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from Bio import SeqIO\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smash = pd.read_csv(\"../misc_data/antismash_db_results.csv\", sep=\"\\t\")\n",
    "smash[smash[\"NCBI accession\"] == \"NC_010612.1\"] \n",
    "counts = smash[\"NCBI accession\"].value_counts()\n",
    "above_10_index = counts[counts > 5].index\n",
    "smash = smash[smash[\"NCBI accession\"].isin(above_10_index)]\n",
    "smash[\"NCBI accession\"] = smash[\"NCBI accession\"].apply(lambda row: row.split(\".\")[0])\n",
    "smash_dict = dict()\n",
    "for accession, df in smash.groupby(\"NCBI accession\"):\n",
    "    smash_dict[accession] = df[[\"From\", \"To\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"antismash_accessions_greater_than_5_bgcs.txt\", \"w\")\n",
    "for i in smash_dict.keys():\n",
    "    f.write(i + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 5\n",
    "k_split = 1\n",
    "top_k = 100\n",
    "\n",
    "def get_splits(k_split, num_splits=5, top_k = 100):\n",
    "\n",
    "    smash = pd.read_csv(\"../misc_data/antismash_db_results.csv\", sep=\"\\t\")\n",
    "    top_k_accessions = smash[\"NCBI accession\"].value_counts()[:top_k].index\n",
    "    # above_10_index = counts[counts > 5].index\n",
    "    smash = smash[smash[\"NCBI accession\"].isin(top_k_accessions)]\n",
    "    smash[\"NCBI accession\"] = smash[\"NCBI accession\"].apply(lambda row: row.split(\".\")[0])\n",
    "    smash_dict = dict()\n",
    "    for accession, df in smash.groupby(\"NCBI accession\"):\n",
    "        smash_dict[accession] = df[[\"From\", \"To\"]].to_numpy()\n",
    "    smash_nums = sorted([(k, len(value)) for k, value in smash_dict.items()], key = lambda tup: tup[1], reverse=True)\n",
    "    random.seed(42)\n",
    "    random.shuffle(smash_nums)\n",
    "    splits = [[] for i in range(num_splits)]\n",
    "    for ix, tup in enumerate(smash_nums):\n",
    "        split = ix % num_splits\n",
    "        splits[split].append(tup[0])\n",
    "\n",
    "    test = splits.pop(k_split)\n",
    "    train = [i for s in splits for i in s]\n",
    "    \n",
    "    test = subprocess.run([\"../scripts/genome_accession_to_patric_genome_ids.sh\"] + test, capture_output=True).stdout.decode(\"utf-8\").split(\"\\n\")\n",
    "    test = [i for i in test if i != \"\"]\n",
    "    \n",
    "    train = subprocess.run([\"../scripts/genome_accession_to_patric_genome_ids.sh\"] + train, capture_output=True).stdout.decode(\"utf-8\").split(\"\\n\")\n",
    "    train = [i for i in train if i != \"\"]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_splits(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [[] for i in range(num_splits)]\n",
    "for ix, tup in enumerate(smash_nums):\n",
    "    split = ix % num_splits\n",
    "    splits[split].append(tup[0])\n",
    "    \n",
    "test = splits.pop(k_split)\n",
    "train = [i for s in splits for i in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smash_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smash_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'19): No such file or directory (os error 2)\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(f\"rg $(rg {'|'.join(top)} ../misc_data/prokaryotes.txt | cut -f 19) ../notebooks/genome_metadata | cut -f 1 \".split(), capture_output=True).stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['439334.465',\n",
       " '189918.11',\n",
       " '2094119.3',\n",
       " '53376.9',\n",
       " '1781.42',\n",
       " '120959.23',\n",
       " '1767.9',\n",
       " '1547487.3',\n",
       " '']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"../scripts/genome_accession_to_patric_genome_ids.sh\"] + top, capture_output=True).stdout.decode(\"utf-8\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(\"rg 'NZ_CP011883|NZ_MPNT01000022|NZ_SDLM01000041|NZ_BFCH01000017|NZ_QAYH01000003|NZ_BFAB01000032|NZ_CP023152|NZ_BFCH01000002|NZ_AP022581|NZ_SDLM01000005' ../misc_data/prokaryotes.txt | grep -v Mycobacterium\".split(),capture_output=True).stdout #| cut -f 19 | tr -d '\\n' | sed 's/.[0-9]G/|G/g'\".split(), capture_output=True, shell=True).stderr.decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rg $(rg NZ_CP011883|NZ_MPNT01000022|NZ_SDLM01000041|NZ_BFCH01000017|NZ_QAYH01000003|NZ_BFAB01000032|NZ_CP023152|NZ_BFCH01000002|NZ_AP022581|NZ_SDLM01000005 ../misc_data/prokaryotes.txt | cut -f 19) ../notebooks/genome_metadata | cut -f 1 '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"rg $(rg {'|'.join(top)} ../misc_data/prokaryotes.txt | cut -f 19) ../notebooks/genome_metadata | cut -f 1 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genome_ids_from_accessions(accessions=[], limit=250000000, stream=False):\n",
    "    \n",
    "    selectors = [\"ne(feature_type)\",\"eq(annotation,PATRIC)\",f\"in(accession,({','.join(accessions)}))\"]\n",
    "    genomes = f\"and({','.join(selectors)})\"    \n",
    "    limit = f\"limit({limit})\"\n",
    "    select = \"select(genome_id,genome_name,accession,annotation,feature_type,patric_id,refseq_locus_tag,alt_locus_tag,uniprotkb_accession,start,end,strand,na_length,gene,product,figfam_id,plfam_id,pgfam_id,go,ec,pathway,aa_sequence_md5)&sort(+genome_id,+sequence_id,+start)\"\n",
    "    base = \"https://www.patricbrc.org/api/genome_feature/\"\n",
    "    query = \"&\".join([genomes, limit, select])\n",
    "    headers = {\"accept\":\"text/tsv\", \"content-type\": \"application/rqlquery+x-www-form-urlencoded\"}\n",
    "\n",
    "    genome_ids = []\n",
    "    \n",
    "    r = requests.post(url=base, data=query, headers=headers, stream=stream)\n",
    "    \n",
    "    if r.encoding is None:\n",
    "        r.encoding = \"utf-8\"\n",
    "    for ix, line in enumerate(r.iter_lines(decode_unicode=True)):\n",
    "        line = line.replace('\"', '')\n",
    "        if ix > 0: \n",
    "            genome_ids.append(line.split()[0])\n",
    "    return list(set(genome_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(data, chunk_size):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i+chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_from_genome_ids(outfile, genome_ids, limit=25000000, stream=False):\n",
    "    with open(outfile, \"w\") as dest:\n",
    "        pass\n",
    "    for gids in chunker(genome_ids, 1):\n",
    "        selectors = [\"ne(feature_type)\",\"eq(annotation,PATRIC)\",f\"in(genome_id,({','.join(gids)}))\"]\n",
    "    #     selectors = [\"ne(feature_type)\",\"eq(annotation,PATRIC)\",f\"in(accession,({','.join(accessions)}))\"]\n",
    "        genomes = f\"and({','.join(selectors)})\"    \n",
    "        limit = f\"limit({limit})\"\n",
    "        select = \"select(genome_id,genome_name,accession,annotation,feature_type,patric_id,refseq_locus_tag,alt_locus_tag,uniprotkb_accession,start,end,strand,na_length,gene,product,figfam_id,plfam_id,pgfam_id,go,ec,pathway,aa_sequence_md5)&sort(+genome_id,+sequence_id,+start)\"\n",
    "        base = \"https://www.patricbrc.org/api/genome_feature/\"\n",
    "        query = \"&\".join([genomes, limit, select])\n",
    "        headers = {\"accept\":\"text/tsv\", \"content-type\": \"application/rqlquery+x-www-form-urlencoded\"}\n",
    "\n",
    "        genome_ids = []\n",
    "\n",
    "        r = requests.post(url=base, data=query, headers=headers, stream=stream)\n",
    "\n",
    "        if r.encoding is None:\n",
    "            r.encoding = \"utf-8\"\n",
    "        with open(outfile, \"a\") as dest:\n",
    "            dest.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_gids = []\n",
    "with open(\"../misc_data/antismash_genome_from_accession_no_plasmid_unique.txt\") as src:\n",
    "    for line in src.readlines():\n",
    "        anti_gids.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_from_genome_ids(\"anti_gids_no_pfams.tsv\", anti_gids[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['216594.6', '1781.42', '1136880.4']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_anti_gids = []\n",
    "with open(\"antismash_top_3_accession_gids.txt\") as src:\n",
    "    for line in src.readlines():\n",
    "        top_3_anti_gids.append(line.strip())\n",
    "top_3_anti_gids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_from_genome_ids(\"top_3_anti_gids_no_pfams.tsv\", top_3_anti_gids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "print(len(smash_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"antismash_genome_ids.txt\", \"w\") as dest:\n",
    "with open(\"antismash_accession_ids.txt\", \"w\") as dest:\n",
    "#     for i in smash_genome_ids:\n",
    "    for i in smash_dict.keys():\n",
    "        dest.write(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [r for r in SeqIO.parse(\"/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/genera/Mycobacterium/jsonhfasta/2021-02-24.jsonhfasta\", \"fasta\")]\n",
    "seq_dict = [json.loads(r.description.split(None, 1)[-1]) for r in records]\n",
    "seq_dict = {x[\"md5\"]:sorted([i for i in x.setdefault(\"sequence_domain\", [{\"source\":\"none\", \"start\":\"0\"}]) if i[\"source\"] == \"pfam\"], key = lambda x: int(x[\"start\"])) for x in seq_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pfam_graph_input(source, destination):\n",
    "    with open(source) as src:\n",
    "        with open(destination, \"w\") as dest:\n",
    "            for ix, line in enumerate(src.readlines()):\n",
    "                vals = line.strip().split(\"\\t\")\n",
    "                if ix == 0:\n",
    "                    names = vals\n",
    "                    name_ids = {name:ix for ix, name in enumerate(names)}\n",
    "                try:\n",
    "                    vals = {name:vals[ix] for ix, name in enumerate(names)}\n",
    "                except:\n",
    "                    continue\n",
    "                md5 = vals[\"aa_sequence_md5\"].replace('\"', '')\n",
    "                pgfam = vals[\"pgfam_id\"]\n",
    "\n",
    "                #This means that the pgfam is NAN and should be skipped\n",
    "                if len(pgfam) < 2:\n",
    "                    continue\n",
    "\n",
    "                dest.write(line)\n",
    "\n",
    "                try:\n",
    "                    pfams = seq_dict[md5]\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                if len(pfams) > 0:\n",
    "                    for pfam in pfams:\n",
    "                        pfam_line = line.split(\"\\t\")\n",
    "                        pfam_line[name_ids[\"start\"]] = str(int(vals['start']) + int(pfam['start']))\n",
    "                        pfam_line[name_ids[\"end\"]] = str(int(vals['start']) + int(pfam['end']))\n",
    "                        pfam_line[name_ids[\"na_length\"]] = str(int(pfam['end']) - int(pfam['start']))\n",
    "                        pfam_line[name_ids[\"pgfam_id\"]] = pfam[\"sequence_domain\"]\n",
    "                        pfam_line[name_ids[\"figfam_id\"]] = pfam[\"sequence_domain\"]\n",
    "                        pfam_line[name_ids[\"plfam_id\"]] = pfam[\"sequence_domain\"]\n",
    "                        pfam_line[name_ids[\"annotation\"]] = \"CUSTOM\"\n",
    "                        dest.write((\"\\t\".join(pfam_line)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pfam_graph_input(\"anti_gids_no_pfams.tsv\", \"anti_gids_with_pfams.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pfam_graph_input(\"top_3_anti_gids_no_pfams.tsv\", \"top_3_anti_gids_with_pfams.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
