{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph import datasets, StellarGraph\n",
    "import networkx as nx\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Cora()\n",
    "G, node_subjects = dataset.load(largest_connected_component_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = KeyedVectors.load(\"../test_data/pgfam_and_pfam_wv_embedding.pkl\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.readwrite.read_gexf(\"../test_data/test-families-and-dists-only.gexf\")\n",
    "\n",
    "for node_id in nx_graph.nodes:\n",
    "    node = nx_graph.nodes[node_id]\n",
    "    family = node[\"family\"]\n",
    "    to_last = node[\"dist_to_last\"]\n",
    "    to_next = node[\"dist_to_next\"]\n",
    "    if type(family) == str:\n",
    "        family = family.replace('\"', \"\")\n",
    "#         print(type(embeddings.wv.get_vector(family)))\n",
    "        node[\"family\"] = np.concatenate(([to_last, to_next],  embeddings.wv.get_vector(family)))\n",
    "    else:\n",
    "#         print(family)\n",
    "        pass\n",
    "\n",
    "for node_id in nx_graph.nodes:\n",
    "    node = nx_graph.nodes[node_id]\n",
    "    if \"label\" in node.keys():\n",
    "        del node[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StellarGraph.from_networkx(nx_graph, node_features=\"family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tups = []\n",
    "for node_id in list(nx_graph.nodes):\n",
    "    class_tups.append((node_id, 1 if nx_graph.nodes[node_id][\"BGC\"] else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgc_labels = pd.DataFrame.from_records(class_tups, columns=[\"id\", \"BGC\"]).set_index(\"id\")[\"BGC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 132112, Edges: 171172\n",
      "\n",
      " Node types:\n",
      "  default: [132112]\n",
      "    Features: float32 vector, length 102\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [171172]\n",
      "        Weights: range=[0.0212766, 0.978723], mean=0.0568194, std=0.0965053\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "dataset = datasets.Cora()\n",
    "display(HTML(dataset.description))\n",
    "G, node_subjects = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 2708, Edges: 5429\n",
      "\n",
      " Node types:\n",
      "  paper: [2708]\n",
      "    Features: float32 vector, length 1433\n",
      "    Edge types: paper-cites->paper\n",
      "\n",
      " Edge types:\n",
      "    paper-cites->paper: [5429]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(G.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31336             Neural_Networks\n",
       "1061127             Rule_Learning\n",
       "1106406    Reinforcement_Learning\n",
       "13195      Reinforcement_Learning\n",
       "37879       Probabilistic_Methods\n",
       "                    ...          \n",
       "1128975        Genetic_Algorithms\n",
       "1128977        Genetic_Algorithms\n",
       "1128978        Genetic_Algorithms\n",
       "117328                 Case_Based\n",
       "24043             Neural_Networks\n",
       "Name: subject, Length: 2708, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Internal Network Test\n",
    "#### Using https://stellargraph.readthedocs.io/en/stable/demos/node-classification/graphsage-node-classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator\n",
    "from stellargraph.layer import GraphSAGE\n",
    "\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from stellargraph import datasets\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgc_metrics = [\n",
    "    metrics.FalseNegatives(name=\"fn\"),\n",
    "    metrics.FalsePositives(name=\"fp\"),\n",
    "    metrics.TrueNegatives(name=\"tn\"),\n",
    "    metrics.TruePositives(name=\"tp\"),\n",
    "    metrics.Precision(name=\"precision\"),\n",
    "    metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "#From https://towardsdatascience.com/implementing-macro-f1-score-in-keras-what-not-to-do-e9f1aa04029d\n",
    "# class F1Metric(Callback):\n",
    "#     def __init__(self, validation):   \n",
    "#         super(Metrics, self).__init__()\n",
    "#         self.validation = validation    \n",
    "            \n",
    "#         print('validation shape', len(self.validation[0]))\n",
    "        \n",
    "#     def on_train_begin(self, logs={}):        \n",
    "#         self.val_f1s = []\n",
    "#         self.val_recalls = []\n",
    "#         self.val_precisions = []\n",
    "     \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         val_targ = self.validation[1]   \n",
    "#         val_predict = (np.asarray(self.model.predict(self.validation[0]))).round()        \n",
    "    \n",
    "#         val_f1 = f1_score(val_targ, val_predict)\n",
    "#         val_recall = recall_score(val_targ, val_predict)         \n",
    "#         val_precision = precision_score(val_targ, val_predict)\n",
    "        \n",
    "#         self.val_f1s.append(round(val_f1, 6))\n",
    "#         self.val_recalls.append(round(val_recall, 6))\n",
    "#         self.val_precisions.append(round(val_precision, 6))\n",
    " \n",
    "#         print(f' — val_f1: {val_f1} — val_precision: {val_precision}, — val_recall: {val_recall}')\n",
    "    \n",
    "#From https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2\n",
    "    \n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
    "        val_targ = self.model.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(\"— val_f1: {} — val_precision: {} — val_recall {}\".format(_val_f1, _val_precision, _val_recall))\n",
    "#         return\n",
    " \n",
    "f1metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/venvs/stellar/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0 1], y=id\n",
      "122927    0\n",
      "45224     1\n",
      "26305     1\n",
      "89373     0\n",
      "29862     0\n",
      "         ..\n",
      "85828     0\n",
      "26003     0\n",
      "64854     0\n",
      "117608    0\n",
      "6695      0\n",
      "Name: BGC, Length: 13211, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "265/265 - 37s - loss: 0.6944 - fn: 276.0000 - fp: 106158.0000 - tn: 23233.0000 - tp: 2445.0000 - precision: 0.0225 - recall: 0.8986 - val_loss: 0.7167 - val_fn: 751.0000 - val_fp: 66170.0000 - val_tn: 50282.0000 - val_tp: 1698.0000 - val_precision: 0.0250 - val_recall: 0.6933\n",
      "Epoch 2/20\n",
      "265/265 - 35s - loss: 0.6921 - fn: 112.0000 - fp: 6368.0000 - tn: 6571.0000 - tp: 160.0000 - precision: 0.0245 - recall: 0.5882 - val_loss: 0.7069 - val_fn: 768.0000 - val_fp: 60565.0000 - val_tn: 55887.0000 - val_tp: 1681.0000 - val_precision: 0.0270 - val_recall: 0.6864\n",
      "Epoch 3/20\n",
      "265/265 - 35s - loss: 0.6936 - fn: 119.0000 - fp: 6425.0000 - tn: 6514.0000 - tp: 153.0000 - precision: 0.0233 - recall: 0.5625 - val_loss: 0.6724 - val_fn: 1092.0000 - val_fp: 45228.0000 - val_tn: 71224.0000 - val_tp: 1357.0000 - val_precision: 0.0291 - val_recall: 0.5541\n",
      "Epoch 4/20\n",
      "265/265 - 35s - loss: 0.6773 - fn: 99.0000 - fp: 6174.0000 - tn: 6765.0000 - tp: 173.0000 - precision: 0.0273 - recall: 0.6360 - val_loss: 0.4940 - val_fn: 2337.0000 - val_fp: 1466.0000 - val_tn: 114986.0000 - val_tp: 112.0000 - val_precision: 0.0710 - val_recall: 0.0457\n",
      "Epoch 5/20\n",
      "265/265 - 35s - loss: 0.6795 - fn: 149.0000 - fp: 4449.0000 - tn: 8490.0000 - tp: 123.0000 - precision: 0.0269 - recall: 0.4522 - val_loss: 1.0242 - val_fn: 2.0000 - val_fp: 116207.0000 - val_tn: 245.0000 - val_tp: 2447.0000 - val_precision: 0.0206 - val_recall: 0.9992\n",
      "Epoch 6/20\n",
      "265/265 - 35s - loss: 0.6642 - fn: 119.0000 - fp: 4928.0000 - tn: 8011.0000 - tp: 153.0000 - precision: 0.0301 - recall: 0.5625 - val_loss: 0.7304 - val_fn: 417.0000 - val_fp: 63741.0000 - val_tn: 52711.0000 - val_tp: 2032.0000 - val_precision: 0.0309 - val_recall: 0.8297\n",
      "Epoch 7/20\n",
      "265/265 - 35s - loss: 0.6619 - fn: 121.0000 - fp: 4554.0000 - tn: 8385.0000 - tp: 151.0000 - precision: 0.0321 - recall: 0.5551 - val_loss: 0.3489 - val_fn: 2351.0000 - val_fp: 657.0000 - val_tn: 115795.0000 - val_tp: 98.0000 - val_precision: 0.1298 - val_recall: 0.0400\n",
      "Epoch 8/20\n",
      "265/265 - 35s - loss: 0.6354 - fn: 133.0000 - fp: 3242.0000 - tn: 9697.0000 - tp: 139.0000 - precision: 0.0411 - recall: 0.5110 - val_loss: 0.7303 - val_fn: 618.0000 - val_fp: 49982.0000 - val_tn: 66470.0000 - val_tp: 1831.0000 - val_precision: 0.0353 - val_recall: 0.7477\n",
      "Epoch 9/20\n",
      "265/265 - 35s - loss: 0.6279 - fn: 120.0000 - fp: 3492.0000 - tn: 9447.0000 - tp: 152.0000 - precision: 0.0417 - recall: 0.5588 - val_loss: 0.3828 - val_fn: 2150.0000 - val_fp: 2644.0000 - val_tn: 113808.0000 - val_tp: 299.0000 - val_precision: 0.1016 - val_recall: 0.1221\n",
      "Epoch 10/20\n",
      "265/265 - 35s - loss: 0.6114 - fn: 121.0000 - fp: 2827.0000 - tn: 10112.0000 - tp: 151.0000 - precision: 0.0507 - recall: 0.5551 - val_loss: 0.4619 - val_fn: 1791.0000 - val_fp: 6846.0000 - val_tn: 109606.0000 - val_tp: 658.0000 - val_precision: 0.0877 - val_recall: 0.2687\n",
      "Epoch 11/20\n",
      "265/265 - 35s - loss: 0.6160 - fn: 120.0000 - fp: 3165.0000 - tn: 9774.0000 - tp: 152.0000 - precision: 0.0458 - recall: 0.5588 - val_loss: 0.8017 - val_fn: 482.0000 - val_fp: 60421.0000 - val_tn: 56031.0000 - val_tp: 1967.0000 - val_precision: 0.0315 - val_recall: 0.8032\n",
      "Epoch 12/20\n",
      "265/265 - 35s - loss: 0.6033 - fn: 98.0000 - fp: 3677.0000 - tn: 9262.0000 - tp: 174.0000 - precision: 0.0452 - recall: 0.6397 - val_loss: 0.3218 - val_fn: 1924.0000 - val_fp: 4592.0000 - val_tn: 111860.0000 - val_tp: 525.0000 - val_precision: 0.1026 - val_recall: 0.2144\n",
      "Epoch 13/20\n",
      "265/265 - 35s - loss: 0.5926 - fn: 111.0000 - fp: 3015.0000 - tn: 9924.0000 - tp: 161.0000 - precision: 0.0507 - recall: 0.5919 - val_loss: 1.2736 - val_fn: 51.0000 - val_fp: 109079.0000 - val_tn: 7373.0000 - val_tp: 2398.0000 - val_precision: 0.0215 - val_recall: 0.9792\n",
      "Epoch 14/20\n",
      "265/265 - 35s - loss: 0.6008 - fn: 104.0000 - fp: 3438.0000 - tn: 9501.0000 - tp: 168.0000 - precision: 0.0466 - recall: 0.6176 - val_loss: 0.9771 - val_fn: 331.0000 - val_fp: 68415.0000 - val_tn: 48037.0000 - val_tp: 2118.0000 - val_precision: 0.0300 - val_recall: 0.8648\n",
      "Epoch 15/20\n",
      "265/265 - 39s - loss: 0.6092 - fn: 97.0000 - fp: 3606.0000 - tn: 9333.0000 - tp: 175.0000 - precision: 0.0463 - recall: 0.6434 - val_loss: 0.4214 - val_fn: 1484.0000 - val_fp: 11213.0000 - val_tn: 105239.0000 - val_tp: 965.0000 - val_precision: 0.0792 - val_recall: 0.3940\n",
      "Epoch 16/20\n",
      "265/265 - 35s - loss: 0.5919 - fn: 96.0000 - fp: 3456.0000 - tn: 9483.0000 - tp: 176.0000 - precision: 0.0485 - recall: 0.6471 - val_loss: 0.4010 - val_fn: 1511.0000 - val_fp: 10599.0000 - val_tn: 105853.0000 - val_tp: 938.0000 - val_precision: 0.0813 - val_recall: 0.3830\n",
      "Epoch 17/20\n",
      "265/265 - 35s - loss: 0.5675 - fn: 86.0000 - fp: 3480.0000 - tn: 9459.0000 - tp: 186.0000 - precision: 0.0507 - recall: 0.6838 - val_loss: 0.3035 - val_fn: 1752.0000 - val_fp: 6237.0000 - val_tn: 110215.0000 - val_tp: 697.0000 - val_precision: 0.1005 - val_recall: 0.2846\n",
      "Epoch 18/20\n",
      "265/265 - 35s - loss: 0.5810 - fn: 100.0000 - fp: 2961.0000 - tn: 9978.0000 - tp: 172.0000 - precision: 0.0549 - recall: 0.6324 - val_loss: 0.4602 - val_fn: 1374.0000 - val_fp: 12447.0000 - val_tn: 104005.0000 - val_tp: 1075.0000 - val_precision: 0.0795 - val_recall: 0.4390\n",
      "Epoch 19/20\n",
      "265/265 - 35s - loss: 0.5782 - fn: 93.0000 - fp: 3353.0000 - tn: 9586.0000 - tp: 179.0000 - precision: 0.0507 - recall: 0.6581 - val_loss: 0.4218 - val_fn: 1572.0000 - val_fp: 8998.0000 - val_tn: 107454.0000 - val_tp: 877.0000 - val_precision: 0.0888 - val_recall: 0.3581\n",
      "Epoch 20/20\n",
      "265/265 - 35s - loss: 0.5913 - fn: 96.0000 - fp: 3204.0000 - tn: 9735.0000 - tp: 176.0000 - precision: 0.0521 - recall: 0.6471 - val_loss: 0.4636 - val_fn: 1307.0000 - val_fp: 13853.0000 - val_tn: 102599.0000 - val_tp: 1142.0000 - val_precision: 0.0762 - val_recall: 0.4663\n"
     ]
    }
   ],
   "source": [
    "train_bgcs, test_bgcs = model_selection.train_test_split(\n",
    "    bgc_labels, train_size=0.1, test_size=None, stratify=bgc_labels\n",
    ")\n",
    "# target_encoding = preprocessing.LabelBinarizer()\n",
    "\n",
    "# train_targets = target_encoding.fit_transform(train_bgcs)\n",
    "# test_targets = target_encoding.transform(test_bgcs)\n",
    "batch_size = 50\n",
    "num_samples = [10, 5]\n",
    "generator = GraphSAGENodeGenerator(graph, batch_size, num_samples)\n",
    "train_gen = generator.flow(train_bgcs.index, train_bgcs, shuffle=True)\n",
    "\n",
    "graphsage_model = GraphSAGE(\n",
    "    layer_sizes=[32, 32], generator=generator, bias=True, dropout=0.5,\n",
    ")\n",
    "\n",
    "x_inp, x_out = graphsage_model.in_out_tensors()\n",
    "prediction = layers.Dense(units=1, activation=\"sigmoid\")(x_out)\n",
    "\n",
    "model = Model(inputs=x_inp, outputs=prediction)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.005),\n",
    "    loss=losses.binary_crossentropy,\n",
    "    metrics=bgc_metrics,\n",
    ")\n",
    "\n",
    "test_gen = generator.flow(test_bgcs.index, test_bgcs)\n",
    "\n",
    "# Calculate the weights for each class so that we can balance the data\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            np.unique(train_bgcs),\n",
    "                                            train_bgcs)\n",
    "weights = {i:weights[i] for i in range(2)}\n",
    "history = model.fit(\n",
    "    train_gen, epochs=20, validation_data=test_gen, verbose=2, shuffle=False, class_weight=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    116452\n",
      "           1       0.08      0.47      0.13      2449\n",
      "\n",
      "    accuracy                           0.87    118901\n",
      "   macro avg       0.53      0.68      0.53    118901\n",
      "weighted avg       0.97      0.87      0.92    118901\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_bgcs, [round(i[0]) for i in y_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Matrix size-incompatible: In[0]: [50,7], In[1]: [32,1]\n\t [[node gradient_tape/model/dense/MatMul (defined at <ipython-input-39-bc9c07c649f0>:31) ]] [Op:__inference_train_function_1699]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-bc9c07c649f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m history = model.fit(\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/venvs/stellar/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/venvs/stellar/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/venvs/stellar/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/venvs/stellar/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/venvs/stellar/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/venvs/stellar/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/sfs/lustre/bahamut/scratch/jho5ze/bionets/BGCs/venvs/stellar/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Matrix size-incompatible: In[0]: [50,7], In[1]: [32,1]\n\t [[node gradient_tape/model/dense/MatMul (defined at <ipython-input-39-bc9c07c649f0>:31) ]] [Op:__inference_train_function_1699]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "train_subjects, test_subjects = model_selection.train_test_split(\n",
    "    node_subjects, train_size=0.1, test_size=None, stratify=node_subjects\n",
    ")\n",
    "target_encoding = preprocessing.LabelBinarizer()\n",
    "\n",
    "train_targets = target_encoding.fit_transform(train_subjects)\n",
    "test_targets = target_encoding.transform(test_subjects)\n",
    "\n",
    "batch_size = 50\n",
    "num_samples = [10, 5]\n",
    "generator = GraphSAGENodeGenerator(G, batch_size, num_samples)\n",
    "train_gen = generator.flow(train_subjects.index, train_targets, shuffle=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stellar",
   "language": "python",
   "name": "stellar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
