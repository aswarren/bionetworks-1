{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../test_data/toy-ppi-G.json\") as src:\n",
    "#     data = json.load(src)\n",
    "#     j = nx.readwrite.json_graph.node_link_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../scripts/test-G.json\") as src:\n",
    "#     data = json.load(src)\n",
    "#     G = nx.readwrite.json_graph.node_link_graph(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smash = pd.read_csv(\"../misc_data/antismash_db_results.csv\", sep=\"\\t\")\n",
    "counts = smash[\"NCBI accession\"].value_counts()\n",
    "# above_10_index = counts[counts > 10].index\n",
    "# smash = smash[smash[\"NCBI accession\"].isin(above_10_index)]\n",
    "smash[\"NCBI accession\"] = smash[\"NCBI accession\"].apply(lambda row: row.split(\".\")[0])\n",
    "smash_dict = dict()\n",
    "for accession, df in smash.groupby(\"NCBI accession\"):\n",
    "    smash_dict[accession] = df[[\"From\", \"To\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.readwrite.read_gexf(\"../test_data/first_pass_split_0_train_pgfams.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_atts = deepcopy(g) #g.nodes[\"60687\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = dict()\n",
    "class_map = dict()\n",
    "for ix, node_id in enumerate(sorted(list(no_atts.nodes))):    \n",
    "    id_map[node_id] = ix\n",
    "    \n",
    "with open(\"test-id_map.json\", \"w\") as dest:\n",
    "    json.dump(id_map, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_arr = []\n",
    "for ix, node_id in enumerate(sorted(list(no_atts.nodes))):    \n",
    "    feat_arr.append(g.nodes[node_id][\"family\"])\n",
    "np.save(\"test-feats.npy\", np.array(feat_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_feature_in_bgc(contig_name, start, stop):\n",
    "    start = int(start)\n",
    "    stop = int(stop)\n",
    "    try:\n",
    "        bgcs = smash_dict[contig_name]\n",
    "    except:\n",
    "        return False\n",
    "    for b_start, b_stop in bgcs:\n",
    "        if (start>= b_start) and (stop <= b_stop):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def annotate_edges(pfams):\n",
    "    for u,v,a in pfams.edges(data=True):\n",
    "        start = pfams.nodes[u]\n",
    "        stop = pfams.nodes[v]\n",
    "        edge_bgc = start[\"BGC\"] and stop[\"BGC\"]\n",
    "        is_start_pfam = start[\"family\"][:2] == \"PF\"\n",
    "        is_stop_pfam = stop[\"family\"][:2] == \"PF\"\n",
    "        if is_start_pfam and is_stop_pfam:\n",
    "            edge_type = \"pfam\"\n",
    "        elif is_start_pfam ^ is_stop_pfam:\n",
    "            edge_type = \"mixed\"\n",
    "        else:\n",
    "            edge_type = \"pgfam\"\n",
    "        a[\"BGC\"] = edge_bgc\n",
    "        a[\"LinkType\"] = edge_type\n",
    "\n",
    "def add_min_dist_and_bgc_features(orig_graph):\n",
    "    g = deepcopy(orig_graph)\n",
    "    for node_id in list(g.nodes):\n",
    "        node_bgc = False\n",
    "        node = g.nodes[node_id]\n",
    "        if type(node[\"features\"]) == str:\n",
    "            features = json.loads(node[\"features\"].replace('\"\"', '\"'))\n",
    "        else:\n",
    "            features = node[\"features\"]\n",
    "        genomes = list(features[\"info\"].keys())\n",
    "        g_dict = features[\"info\"]\n",
    "        \n",
    "        #Usually there is only one segment per genome, but \n",
    "        #just in case, take the first one for start and last for end\n",
    "        \n",
    "        genomes_start = {genome:min([seg[\"start\"] \\\n",
    "                               for chrom in g_dict[genome].keys() \\\n",
    "                               for seg in g_dict[genome][chrom]]) \\\n",
    "                               for genome in genomes}\n",
    "        genomes_end = {genome:max([seg[\"end\"] \\\n",
    "                               for chrom in g_dict[genome].keys() \\\n",
    "                               for seg in g_dict[genome][chrom]]) \\\n",
    "                               for genome in genomes}\n",
    "        \n",
    "        for genome in features[\"info\"]:\n",
    "            if node_bgc:\n",
    "                break\n",
    "            for contig in features[\"info\"][genome]:\n",
    "                if node_bgc:\n",
    "                    break\n",
    "                for ix, sequence in enumerate(features[\"info\"][genome][contig]):\n",
    "                    is_in_bgc = is_feature_in_bgc(contig, sequence[\"start\"], sequence[\"end\"])\n",
    "                    features[\"info\"][genome][contig][ix][\"in_bgc\"] = is_in_bgc\n",
    "                    if is_in_bgc:\n",
    "                        node_bgc = True\n",
    "                        break\n",
    "\n",
    "        node[\"features\"] = features\n",
    "        node[\"BGC\"] = node_bgc\n",
    "        \n",
    "        min_previous_gene = (\"\", float(\"inf\"))\n",
    "        min_next_gene = (\"\", float(\"inf\"))\n",
    "        \n",
    "        for neighbor_id in g.neighbors(node_id):\n",
    "            neighbor = g.nodes[neighbor_id]\n",
    "            if type(neighbor[\"features\"]) == str:\n",
    "                neighbor_features = json.loads(neighbor[\"features\"].replace('\"\"', '\"'))\n",
    "            else:\n",
    "                neighbor_features = neighbor[\"features\"]\n",
    "            ng_dict = neighbor_features[\"info\"]\n",
    "            neighbor_genomes_start = {genome:min([seg[\"start\"] \\\n",
    "                                            for chrom in ng_dict[genome].keys() \\\n",
    "                                            for seg in ng_dict[genome][chrom]]) \\\n",
    "                                    for genome in ng_dict.keys()}\n",
    "            \n",
    "            neighbor_genomes_end = {genome:max([seg[\"end\"] \\\n",
    "                                            for chrom in ng_dict[genome].keys() \\\n",
    "                                            for seg in ng_dict[genome][chrom]]) \\\n",
    "                                    for genome in ng_dict.keys()}\n",
    "            \n",
    "            for neighbor_genome in neighbor_genomes_start:\n",
    "                ng_start = neighbor_genomes_start[neighbor_genome]\n",
    "                ng_end = neighbor_genomes_end[neighbor_genome]\n",
    "                if neighbor_genome in genomes:\n",
    "                    g_start = (genomes_start[neighbor_genome])\n",
    "                    g_end = (genomes_end[neighbor_genome])\n",
    "                    dist = g_start - ng_start\n",
    "                    if dist < 0: #The neighbor is after the main node\n",
    "                        dist = max(0, ng_start - g_end)\n",
    "                        if dist < min_next_gene[1]:\n",
    "                            min_next_gene = (neighbor_genome, dist)\n",
    "                    else: #The main node is after the neighbor\n",
    "                        dist = max(0, g_start - ng_end)\n",
    "                        if dist < min_previous_gene[1]:\n",
    "                            min_previous_gene = (neighbor_genome, dist)\n",
    "                            \n",
    "        if float(\"inf\") == min_previous_gene[1]:\n",
    "            node[\"dist_to_last\"] = 0\n",
    "        else:\n",
    "            node[\"dist_to_last\"] = min_previous_gene[1]\n",
    "        \n",
    "        if float(\"inf\") == min_next_gene[1]:\n",
    "            node[\"dist_to_next\"] = 0\n",
    "        else:\n",
    "            node[\"dist_to_next\"] = min_next_gene[1]\n",
    "    return g\n",
    "    \n",
    "\n",
    "def bare_graph(orig_graph, retain_features=[]):\n",
    "    graph = deepcopy(orig_graph)\n",
    "    for node in list(graph.nodes):\n",
    "        node = graph.nodes[node]\n",
    "        for key in list(node.keys()):\n",
    "            if key not in retain_features:\n",
    "                del node[key]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-90-c7ec7eef29e2>(72)add_min_dist_and_bgc_features()\n",
      "-> min_previous_gene = (\"\", float(\"inf\"))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    }
   ],
   "source": [
    "t = add_min_dist_and_bgc_features(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-90-c7ec7eef29e2>(72)add_min_dist_and_bgc_features()\n",
      "-> min_previous_gene = (\"\", float(\"inf\"))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  c\n"
     ]
    }
   ],
   "source": [
    "family_dists_graph = add_min_dist_and_bgc_features(g)\n",
    "family_dists_graph = bare_graph(family_dists_graph, retain_features=[\"BGC\", \"family\", \"dist_to_last\", \"dist_to_next\"])\n",
    "nx.readwrite.write_gexf(family_dists_graph, \"../test_data/test-families-and-dists-only-pgfams.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_family = bare_graph(g, retain_features=[\"family\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../test_data/test-families-only.gexf\", \"w\") as dest:\n",
    "nx.readwrite.write_gexf(g_family, \"../test_data/test-families-only.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family': 'PF16450'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_family.nodes[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(no_atts.nodes)\n",
    "random.seed(42)\n",
    "random.shuffle(nodes)\n",
    "\n",
    "val_percent = 10\n",
    "test_percent = 20\n",
    "\n",
    "num_records = len(nodes)\n",
    "\n",
    "val_start = int(num_records * (1 - (val_percent + test_percent)/100))\n",
    "test_start = int(num_records * (1 - test_percent/100))\n",
    "\n",
    "for ix, node in enumerate(nodes):\n",
    "#     no_atts[node] = {\"val\":False, \"test\":False}\n",
    "    node = no_atts.nodes[node]\n",
    "    keys = list(node.keys())\n",
    "    for key in keys:\n",
    "        if key not in [\"val\", \"test\"]:\n",
    "            del node[key]\n",
    "    if ix > test_start:\n",
    "        node[\"test\"] = True\n",
    "        node[\"val\"] = False\n",
    "    elif ix > val_start:\n",
    "        node[\"test\"] = False\n",
    "        node[\"val\"] = True\n",
    "    else:\n",
    "        node[\"test\"] = False\n",
    "        node[\"val\"] = False\n",
    "    for att in [\"viz\", \"position\", \"size\"]:\n",
    "        try:\n",
    "            del node[att]\n",
    "        except:\n",
    "            pass\n",
    "#     break\n",
    "#     del node[\"viz\"]    \n",
    "#     del node[\"position\"]    \n",
    "#     del node[\"size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"test-G.json\", \"w\") as dest:\n",
    "#     json.dump(nx.readwrite.json_graph.node_link_data(no_atts), dest)\n",
    "nx.readwrite.write_gexf(no_atts, \"test-G.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"test-G.json\", \"w\") as dest:\n",
    "#     json.dump(nx.readwrite.json_graph.node_link_data(no_atts), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nx.readwrite.json_graph.node_link_graph(json.load(open(\"test-G.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.readwrite.json_graph.node_link_data(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
